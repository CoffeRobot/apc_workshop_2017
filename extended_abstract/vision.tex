\section{Vision}
\label{sec:vision}

\subsection{Simtrack}

We created high-quality 3D textured models from all objects provided for the challenge using the approach described in~\cite{pokorny_2017}. To summarize briefly, each object is placed on a textured background consisting of a collection of newspapers and approximately 40 pictures are taken from various angles. The object is then constructed using Autodesk123D catch services~\cite{autodesk} and postprocessed to separate it from the background, remove holes, reduce the mesh resolution, etc. For the texture-based detection discussed next, we also extracted SIFT-keypoints~\cite{lowe04} from images synthesized by rendering the model from multiple viewpoints. The final object models were used for detection and grasp planning.

A large proportion of the challenge objects contained sufficient texture for keypoint-based pose detection. When such objects were present in the bin, we relied on a texture-based pose estimation method. We used high resolution images obtained from a Logitech~C920 webcam mounted on the robot head. We processed a central 1152$\times$768 pixel region of the full 2304$\times$1536 input image for object detection. The robot head was always oriented towards the bin under consideration so that this region of interest was guaranteed to contain the objects. Our object pose detection framework, SimTrack, first extracts SIFT-features from the image and matches these to the database of SIFT features extracted from the object models in the modeling stage. In the detection stage, the objects are identified, and a rough initial pose is obtained. This pose is then iteratively refined by rendering the textured object models at the current pose  estimate, and locally matching their appearance to the observed image~\cite{pauwels_simtrack_2015}. SimTrack uses a phase-based optical flow algorithm in this refinement (or tracking) stage to reduce sensitivity to intensity differences between model and observed image. SimTrack exploits the rich appearance and shape information of the models and correctly handles occlusions within and between objects. SimTrack is publicly available as a ROS module~\cite{simtrack_github}.


\subsection{Volumetric Reasoning}

We designed a fallback strategy based on 3D point cloud volumetric reasoning in case our system could not recognize the objects using SimTrack. Knowing the location of the shelf and the bins, as shown in Fig.~\ref{fig:localization}, we use the PR2 tilting laser scanner mounted on the torso to build an accurate point cloud within the target bin. We use the 3D model of the shelf and its estimated location to remove any point belonging to the shelf from the constructed point cloud to obtain a cloud of the inside of a bin. Then, we  apply euclidean clustering to generate plausible object hypothesis. Given that the number of objects in the bin is known, we apply our clustering strategy iteratively, increasing the distance threshold, in order to obtain as many clusters as the expected number of objects. Once the clusters are found we formulate the problem of finding the right object to pick as a bi-partite graph matching problem where the nodes on one side are the found clusters characterized by their volumes and the nodes on the other side are the 3D models of the expected objects and their corresponding volumes.